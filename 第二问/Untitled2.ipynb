{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12a2c66d-65f4-4464-88b3-0c306e93d47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据基本信息:\n",
      "             孕妇BMI       Y染色体浓度\n",
      "count  1082.000000  1082.000000\n",
      "mean     32.288791     0.077187\n",
      "std       2.972432     0.033518\n",
      "min      20.703125     0.010004\n",
      "25%      30.208806     0.051381\n",
      "50%      31.811598     0.075066\n",
      "75%      33.926237     0.098937\n",
      "max      46.875000     0.234218\n",
      "\n",
      "检查无穷值:\n",
      "BMI无穷值: 0\n",
      "Y浓度无穷值: 0\n",
      "\n",
      "检查NaN值:\n",
      "BMI NaN值: 0\n",
      "Y浓度 NaN值: 0\n",
      "\n",
      "清洗后数据量: 1082/1082\n",
      "回归方程: Y = -0.001706 * BMI + 0.132276\n",
      "BMI分组界点: [29.95648448 31.16443416 32.67554956 34.44531691]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_14640\\4095373447.py:66: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for name, group in df_clean.groupby('BMI_group'):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "最终结果:\n",
      "          BMI_group  sample_size    best_GA     CI_low    CI_high\n",
      "0     [0.0, 29.956)          217  25.219908  24.182003  27.294812\n",
      "1  [29.956, 31.164)          216  23.558623  22.958786  24.079955\n",
      "2  [31.164, 32.676)          216  22.215133  21.471846  22.867783\n",
      "3  [32.676, 34.445)          216  20.570890  19.731047  21.351637\n",
      "4     [34.445, inf)          217  17.339131  10.319843  19.556189\n",
      "\n",
      "结果已保存到 'NIPT_BMI_group_result.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 1. 彻底检查和处理数据问题\n",
    "print(\"数据基本信息:\")\n",
    "print(df[['孕妇BMI', 'Y染色体浓度']].describe())\n",
    "\n",
    "# 检查是否有无穷大或异常值\n",
    "print(\"\\n检查无穷值:\")\n",
    "print(\"BMI无穷值:\", np.isinf(df['孕妇BMI']).sum())\n",
    "print(\"Y浓度无穷值:\", np.isinf(df['Y染色体浓度']).sum())\n",
    "\n",
    "print(\"\\n检查NaN值:\")\n",
    "print(\"BMI NaN值:\", df['孕妇BMI'].isnull().sum())\n",
    "print(\"Y浓度 NaN值:\", df['Y染色体浓度'].isnull().sum())\n",
    "\n",
    "# 处理任何可能的异常值\n",
    "df_clean = df.copy()\n",
    "df_clean['孕妇BMI'] = df_clean['孕妇BMI'].replace([np.inf, -np.inf], np.nan)\n",
    "df_clean['Y染色体浓度'] = df_clean['Y染色体浓度'].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# 删除包含NaN的行\n",
    "df_clean = df_clean.dropna(subset=['孕妇BMI', 'Y染色体浓度'])\n",
    "print(f\"\\n清洗后数据量: {len(df_clean)}/{len(df)}\")\n",
    "\n",
    "# 2. 线性回归分析\n",
    "X = df_clean[['孕妇BMI']]\n",
    "y = df_clean['Y染色体浓度']\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "a = model.coef_[0]\n",
    "c = model.intercept_\n",
    "print(f\"回归方程: Y = {a:.6f} * BMI + {c:.6f}\")\n",
    "\n",
    "# 3. 使用分位数进行BMI分组\n",
    "k = 5\n",
    "bmi_cutoffs = np.quantile(df_clean['孕妇BMI'], [0.2, 0.4, 0.6, 0.8])\n",
    "print(\"BMI分组界点:\", bmi_cutoffs)\n",
    "\n",
    "# 4. 创建分组\n",
    "df_clean['BMI_group'] = pd.cut(df_clean['孕妇BMI'], \n",
    "                              bins=[0] + list(bmi_cutoffs) + [np.inf], \n",
    "                              right=False)\n",
    "\n",
    "# 5. 计算每组的最佳检测时点\n",
    "def calc_GAmin(Y_target, bmi):\n",
    "    \"\"\"计算达到目标Y浓度所需的最小GA\"\"\"\n",
    "    return (Y_target - c - a * bmi) / a\n",
    "\n",
    "def best_GA_for_group(group_df, Y_target=0.04, coverage=0.95):\n",
    "    sigma_b = 0.01\n",
    "    n_sim = 1000\n",
    "    GA_samples = []\n",
    "    for _, row in group_df.iterrows():\n",
    "        bmi = row['孕妇BMI']\n",
    "        sims = calc_GAmin(Y_target, bmi) + np.random.normal(0, sigma_b, n_sim)\n",
    "        GA = np.percentile(sims, (1 - coverage) * 100)\n",
    "        GA_samples.append(GA)\n",
    "    return np.mean(GA_samples), np.percentile(GA_samples, 2.5), np.percentile(GA_samples, 97.5)\n",
    "\n",
    "# 6. 计算并输出结果\n",
    "result_list = []\n",
    "for name, group in df_clean.groupby('BMI_group'):\n",
    "    GA_mean, GA_low, GA_high = best_GA_for_group(group)\n",
    "    result_list.append({\n",
    "        'BMI_group': str(name),\n",
    "        'sample_size': len(group),\n",
    "        'best_GA': GA_mean,\n",
    "        'CI_low': GA_low,\n",
    "        'CI_high': GA_high\n",
    "    })\n",
    "\n",
    "result_df = pd.DataFrame(result_list)\n",
    "print(\"\\n最终结果:\")\n",
    "print(result_df)\n",
    "\n",
    "# 7. 保存结果\n",
    "result_df.to_excel('NIPT_BMI_group_result.xlsx', index=False)\n",
    "print(\"\\n结果已保存到 'NIPT_BMI_group_result.xlsx'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1af3027b-1356-485a-8dc9-2a5d24367e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "缺失值统计:\n",
      "孕妇BMI     0\n",
      "Y染色体浓度    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"缺失值统计:\")\n",
    "print(df[['孕妇BMI', 'Y染色体浓度']].isnull().sum())\n",
    "\n",
    "# 方法1：删除含有缺失值的行（如果数据量足够大）\n",
    "df_clean = df.dropna(subset=['孕妇BMI', 'Y染色体浓度'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e270805-39ce-4ed4-a9a0-fab4c248e62a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY染色体浓度\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     25\u001b[0m model \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[1;32m---> 26\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X, y)\n\u001b[0;32m     28\u001b[0m a, b \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcoef_\n\u001b[0;32m     29\u001b[0m c \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mintercept_\n",
      "File \u001b[1;32mD:\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:601\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    597\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    599\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 601\u001b[0m X, y \u001b[38;5;241m=\u001b[39m validate_data(\n\u001b[0;32m    602\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    603\u001b[0m     X,\n\u001b[0;32m    604\u001b[0m     y,\n\u001b[0;32m    605\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m    606\u001b[0m     y_numeric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    607\u001b[0m     multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    608\u001b[0m     force_writeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    609\u001b[0m )\n\u001b[0;32m    611\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[1;32mD:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2961\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2959\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m   2960\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2961\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m   2962\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mD:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1370\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1366\u001b[0m     )\n\u001b[0;32m   1368\u001b[0m ensure_all_finite \u001b[38;5;241m=\u001b[39m _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[1;32m-> 1370\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1371\u001b[0m     X,\n\u001b[0;32m   1372\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   1373\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1374\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1375\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   1376\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1377\u001b[0m     force_writeable\u001b[38;5;241m=\u001b[39mforce_writeable,\n\u001b[0;32m   1378\u001b[0m     ensure_all_finite\u001b[38;5;241m=\u001b[39mensure_all_finite,\n\u001b[0;32m   1379\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m   1380\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[0;32m   1381\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1382\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[0;32m   1383\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1384\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1385\u001b[0m )\n\u001b[0;32m   1387\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1389\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mD:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1107\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[1;32m-> 1107\u001b[0m     _assert_all_finite(\n\u001b[0;32m   1108\u001b[0m         array,\n\u001b[0;32m   1109\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m   1110\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m   1111\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mensure_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1112\u001b[0m     )\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1116\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:120\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m _assert_all_finite_element_wise(\n\u001b[0;32m    121\u001b[0m     X,\n\u001b[0;32m    122\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n\u001b[0;32m    123\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[0;32m    124\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n\u001b[0;32m    125\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    126\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    127\u001b[0m )\n",
      "File \u001b[1;32mD:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:169\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    168\u001b[0m     )\n\u001b[1;32m--> 169\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import root_scalar\n",
    "from scipy.stats import norm\n",
    "\n",
    "# -------------------------------\n",
    "# 1. 读取数据\n",
    "# -------------------------------\n",
    "df = pd.read_excel('male.xlsx')\n",
    "\n",
    "# 确认列名一致\n",
    "# df.columns\n",
    "\n",
    "# -------------------------------\n",
    "# 2. 计算Y染色体达标时间\n",
    "# 模型: Yij = f(GAij, BMIi, β) + bi + ϵij\n",
    "# 我们用线性近似 f(GA,BMI)=a*GA+b*BMI+c\n",
    "# -------------------------------\n",
    "# 线性近似拟合 Y ~ GA + BMI\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = df[['检测孕周', '孕妇BMI']]\n",
    "y = df['Y染色体浓度']\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "a, b = model.coef_\n",
    "c = model.intercept_\n",
    "\n",
    "# 定义个体达标函数\n",
    "def calc_GAmin(Y_target, BMIi):\n",
    "    # Y = a*GA + b*BMI + c => GA = (Y - b*BMI - c)/a\n",
    "    return (Y_target - b*BMIi - c)/a\n",
    "\n",
    "df['GA_min'] = df['孕妇BMI'].apply(lambda bmi: calc_GAmin(0.04, bmi))\n",
    "# 对未达标设定右截断 25 周\n",
    "df['GA_min'] = df['GA_min'].apply(lambda x: x if x <= 25 else 25)\n",
    "\n",
    "# -------------------------------\n",
    "# 3. BMI分组动态规划优化\n",
    "# -------------------------------\n",
    "def dp_bmi_group(df, k):\n",
    "    # 排序BMI\n",
    "    df_sorted = df.sort_values('孕妇BMI').reset_index(drop=True)\n",
    "    BMI = df_sorted['孕妇BMI'].values\n",
    "    GAmin = df_sorted['GA_min'].values\n",
    "    n = len(BMI)\n",
    "    \n",
    "    # 预计算区间方差\n",
    "    var_matrix = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            var_matrix[i,j] = np.var(GAmin[i:j+1])\n",
    "    \n",
    "    # DP初始化\n",
    "    dp = np.full((k, n), np.inf)\n",
    "    track = np.zeros((k, n), dtype=int)\n",
    "    \n",
    "    for i in range(n):\n",
    "        dp[0,i] = var_matrix[0,i]\n",
    "    \n",
    "    for group in range(1, k):\n",
    "        for i in range(group, n):\n",
    "            for j in range(group-1, i):\n",
    "                cost = dp[group-1,j] + var_matrix[j+1,i]\n",
    "                if cost < dp[group,i]:\n",
    "                    dp[group,i] = cost\n",
    "                    track[group,i] = j\n",
    "    \n",
    "    # 回溯分组界点\n",
    "    borders = []\n",
    "    idx = n-1\n",
    "    for group in reversed(range(1, k)):\n",
    "        j = track[group, idx]\n",
    "        borders.append(BMI[j])\n",
    "        idx = j\n",
    "    borders = sorted(borders)\n",
    "    return borders\n",
    "\n",
    "# 假设 k=5\n",
    "k = 5\n",
    "bmi_cutoffs = dp_bmi_group(df, k)\n",
    "print(\"BMI分组界点:\", bmi_cutoffs)\n",
    "\n",
    "# -------------------------------\n",
    "# 4. 计算每组最佳检测时点\n",
    "# -------------------------------\n",
    "df['BMI_group'] = pd.cut(df['孕妇BMI'], bins=[0]+bmi_cutoffs+[np.inf], right=False)\n",
    "\n",
    "def best_GA_for_group(group_df, Y_target=0.04, coverage=0.95):\n",
    "    # 模拟随机效应 bi ~ N(0, σb^2)\n",
    "    # 简化假设 σb = 0.01\n",
    "    sigma_b = 0.01\n",
    "    n_sim = 1000\n",
    "    GA_samples = []\n",
    "    for _, row in group_df.iterrows():\n",
    "        bmi = row['孕妇BMI']\n",
    "        sims = calc_GAmin(Y_target, bmi) + np.random.normal(0, sigma_b, n_sim)\n",
    "        # 取使得达标概率 >= coverage 的最小GA\n",
    "        GA = np.percentile(sims, (1-coverage)*100)\n",
    "        GA_samples.append(GA)\n",
    "    return np.mean(GA_samples), np.percentile(GA_samples, 2.5), np.percentile(GA_samples, 97.5)\n",
    "\n",
    "result_list = []\n",
    "for name, group in df.groupby('BMI_group'):\n",
    "    GA_mean, GA_low, GA_high = best_GA_for_group(group)\n",
    "    result_list.append({\n",
    "        'BMI_group': str(name),\n",
    "        'sample_size': len(group),\n",
    "        'best_GA': GA_mean,\n",
    "        'CI_low': GA_low,\n",
    "        'CI_high': GA_high\n",
    "    })\n",
    "\n",
    "result_df = pd.DataFrame(result_list)\n",
    "print(result_df)\n",
    "\n",
    "# -------------------------------\n",
    "# 5. 保存结果\n",
    "# -------------------------------\n",
    "result_df.to_excel('NIPT_BMI_group_result.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5450f908-b06c-46d0-915c-a2934b863a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据基本信息:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1082 entries, 0 to 1081\n",
      "Data columns (total 31 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   序号            1082 non-null   int64  \n",
      " 1   孕妇代码          1082 non-null   object \n",
      " 2   年龄            1082 non-null   int64  \n",
      " 3   身高            1082 non-null   float64\n",
      " 4   体重            1082 non-null   float64\n",
      " 5   末次月经          1082 non-null   object \n",
      " 6   IVF妊娠         1082 non-null   object \n",
      " 7   检测日期          1082 non-null   object \n",
      " 8   检测抽血次数        1082 non-null   int64  \n",
      " 9   检测孕周          1081 non-null   float64\n",
      " 10  孕妇BMI         1082 non-null   float64\n",
      " 11  原始读段数         1082 non-null   int64  \n",
      " 12  在参考基因组上比对的比例  1082 non-null   float64\n",
      " 13  重复读段的比例       1082 non-null   float64\n",
      " 14  唯一比对的读段数      1082 non-null   int64  \n",
      " 15  GC含量          1082 non-null   float64\n",
      " 16  13号染色体的Z值     1082 non-null   float64\n",
      " 17  18号染色体的Z值     1082 non-null   float64\n",
      " 18  21号染色体的Z值     1082 non-null   float64\n",
      " 19  X染色体的Z值       1082 non-null   float64\n",
      " 20  Y染色体的Z值       1082 non-null   float64\n",
      " 21  Y染色体浓度        1082 non-null   float64\n",
      " 22  X染色体浓度        1082 non-null   float64\n",
      " 23  13号染色体的GC含量   1082 non-null   float64\n",
      " 24  18号染色体的GC含量   1082 non-null   float64\n",
      " 25  21号染色体的GC含量   1082 non-null   float64\n",
      " 26  被过滤掉读段数的比例    1082 non-null   float64\n",
      " 27  染色体的非整倍体      1082 non-null   object \n",
      " 28  怀孕次数          1082 non-null   object \n",
      " 29  生产次数          1082 non-null   int64  \n",
      " 30  胎儿是否健康        1082 non-null   object \n",
      "dtypes: float64(18), int64(6), object(7)\n",
      "memory usage: 262.2+ KB\n",
      "None\n",
      "\n",
      "前5行数据:\n",
      "   序号  孕妇代码  年龄     身高    体重                 末次月经 IVF妊娠      检测日期  检测抽血次数  \\\n",
      "0   1  A001  31  160.0  72.0  2023-02-01 00:00:00  自然受孕  20230429       1   \n",
      "1   2  A001  31  160.0  73.0  2023-02-01 00:00:00  自然受孕  20230531       2   \n",
      "2   3  A001  31  160.0  73.0  2023-02-01 00:00:00  自然受孕  20230625       3   \n",
      "3   4  A001  31  160.0  74.0  2023-02-01 00:00:00  自然受孕  20230716       4   \n",
      "4   5  A002  32  149.0  74.0  2023-11-09 00:00:00  自然受孕  20240219       1   \n",
      "\n",
      "        检测孕周  ...    Y染色体浓度    X染色体浓度  13号染色体的GC含量  18号染色体的GC含量  21号染色体的GC含量  \\\n",
      "0  11.857143  ...  0.025936  0.038061     0.377069     0.389803     0.399399   \n",
      "1  15.857143  ...  0.034887  0.059572     0.371542     0.384771     0.391706   \n",
      "2  20.142857  ...  0.066171  0.075995     0.377449     0.390582     0.399480   \n",
      "3  22.857143  ...  0.061192  0.052305     0.375613     0.389251     0.397212   \n",
      "4  13.857143  ...  0.059230  0.059708     0.380260     0.393618     0.404868   \n",
      "\n",
      "   被过滤掉读段数的比例  染色体的非整倍体  怀孕次数  生产次数  胎儿是否健康  \n",
      "0    0.027484         0     1     0       是  \n",
      "1    0.019617         0     1     0       是  \n",
      "2    0.022312         0     1     0       是  \n",
      "3    0.023280         0     1     0       是  \n",
      "4    0.024212         0     2     1       否  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "\n",
      "无穷值检查:\n",
      "孕妇BMI     0\n",
      "Y染色体浓度    0\n",
      "dtype: int64\n",
      "处理后的缺失值统计: 0 0\n",
      "处理后的无穷值统计: 0 0\n",
      "回归方程: Y = -0.001706 * BMI + 0.132276\n",
      "BMI分组界点: [np.float64(28.125), np.float64(28.515625), np.float64(28.515625), np.float64(28.90625)]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Bin edges must be unique: Index([0.0, 28.125, 28.515625, 28.515625, 28.90625, inf], dtype='float64').\nYou can drop duplicate edges by setting the 'duplicates' kwarg",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 96\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBMI分组界点:\u001b[39m\u001b[38;5;124m\"\u001b[39m, bmi_cutoffs)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# 4. 计算每组最佳检测时点\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n\u001b[1;32m---> 96\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBMI_group\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mcut(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m孕妇BMI\u001b[39m\u001b[38;5;124m'\u001b[39m], bins\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39mbmi_cutoffs\u001b[38;5;241m+\u001b[39m[np\u001b[38;5;241m.\u001b[39minf], right\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbest_GA_for_group\u001b[39m(group_df, Y_target\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.04\u001b[39m, coverage\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.95\u001b[39m):\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;66;03m# 模拟随机效应 bi ~ N(0, σb^2)\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# 简化假设 σb = 0.01\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     sigma_b \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\reshape\\tile.py:257\u001b[0m, in \u001b[0;36mcut\u001b[1;34m(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m bins\u001b[38;5;241m.\u001b[39mis_monotonic_increasing:\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbins must increase monotonically.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 257\u001b[0m fac, bins \u001b[38;5;241m=\u001b[39m _bins_to_cuts(\n\u001b[0;32m    258\u001b[0m     x_idx,\n\u001b[0;32m    259\u001b[0m     bins,\n\u001b[0;32m    260\u001b[0m     right\u001b[38;5;241m=\u001b[39mright,\n\u001b[0;32m    261\u001b[0m     labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m    262\u001b[0m     precision\u001b[38;5;241m=\u001b[39mprecision,\n\u001b[0;32m    263\u001b[0m     include_lowest\u001b[38;5;241m=\u001b[39minclude_lowest,\n\u001b[0;32m    264\u001b[0m     duplicates\u001b[38;5;241m=\u001b[39mduplicates,\n\u001b[0;32m    265\u001b[0m     ordered\u001b[38;5;241m=\u001b[39mordered,\n\u001b[0;32m    266\u001b[0m )\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _postprocess_for_cut(fac, bins, retbins, original)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\reshape\\tile.py:443\u001b[0m, in \u001b[0;36m_bins_to_cuts\u001b[1;34m(x_idx, bins, right, labels, precision, include_lowest, duplicates, ordered)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_bins) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(bins) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(bins) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m duplicates \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 443\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    444\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBin edges must be unique: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(bins)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    445\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can drop duplicate edges by setting the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduplicates\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m kwarg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    446\u001b[0m         )\n\u001b[0;32m    447\u001b[0m     bins \u001b[38;5;241m=\u001b[39m unique_bins\n\u001b[0;32m    449\u001b[0m side: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m right \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Bin edges must be unique: Index([0.0, 28.125, 28.515625, 28.515625, 28.90625, inf], dtype='float64').\nYou can drop duplicate edges by setting the 'duplicates' kwarg"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# -------------------------------\n",
    "# 1. 数据准备和回归分析\n",
    "# -------------------------------\n",
    "# 假设df已经包含数据\n",
    "print(\"数据基本信息:\")\n",
    "print(df.info())\n",
    "print(\"\\n前5行数据:\")\n",
    "print(df.head())\n",
    "\n",
    "# 检查是否有无穷大值\n",
    "print(\"\\n无穷值检查:\")\n",
    "print(np.isinf(df[['孕妇BMI', 'Y染色体浓度']]).sum())\n",
    "\n",
    "# 确保数据类型正确\n",
    "X = df[['孕妇BMI']].astype(float)  # 明确转换为float类型\n",
    "y = df['Y染色体浓度'].astype(float)\n",
    "\n",
    "# 再次检查是否有NaN或inf\n",
    "print(\"处理后的缺失值统计:\", X.isnull().sum().sum(), y.isnull().sum())\n",
    "print(\"处理后的无穷值统计:\", np.isinf(X).sum().sum(), np.isinf(y).sum())\n",
    "\n",
    "# 如果有无穷值，处理它们\n",
    "if np.isinf(X).sum().sum() > 0 or np.isinf(y).sum() > 0:\n",
    "    # 替换无穷值为NaN然后填充\n",
    "    X = X.replace([np.inf, -np.inf], np.nan)\n",
    "    y = y.replace([np.inf, -np.inf], np.nan)\n",
    "    # 使用中位数填充\n",
    "    X = X.fillna(X.median())\n",
    "    y = y.fillna(y.median())\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# 修正这里：model.coef_ 是一个数组，不是两个值\n",
    "a = model.coef_[0]  # 获取第一个系数\n",
    "c = model.intercept_\n",
    "print(f\"回归方程: Y = {a:.6f} * BMI + {c:.6f}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 2. 定义计算最小GA的函数\n",
    "# -------------------------------\n",
    "def calc_GAmin(Y_target, bmi):\n",
    "    \"\"\"计算达到目标Y浓度所需的最小GA\"\"\"\n",
    "    return (Y_target - c - a * bmi) / a  # 修正：使用a而不是b\n",
    "\n",
    "# -------------------------------\n",
    "# 3. 动态规划分组（保持原有代码）\n",
    "# -------------------------------\n",
    "def dp_bmi_group(df, k):\n",
    "    n = len(df)\n",
    "    BMI = df['孕妇BMI'].values\n",
    "    \n",
    "    # 计算方差矩阵\n",
    "    var_matrix = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            var_matrix[i,j] = np.var(BMI[i:j+1])\n",
    "    \n",
    "    # DP初始化\n",
    "    dp = np.full((k, n), np.inf)\n",
    "    track = np.zeros((k, n), dtype=int)\n",
    "    \n",
    "    for i in range(n):\n",
    "        dp[0,i] = var_matrix[0,i]\n",
    "    \n",
    "    for group in range(1, k):\n",
    "        for i in range(group, n):\n",
    "            for j in range(group-1, i):\n",
    "                cost = dp[group-1,j] + var_matrix[j+1,i]\n",
    "                if cost < dp[group,i]:\n",
    "                    dp[group,i] = cost\n",
    "                    track[group,i] = j\n",
    "    \n",
    "    # 回溯分组界点\n",
    "    borders = []\n",
    "    idx = n-1\n",
    "    for group in reversed(range(1, k)):\n",
    "        j = track[group, idx]\n",
    "        borders.append(BMI[j])\n",
    "        idx = j\n",
    "    borders = sorted(borders)\n",
    "    return borders\n",
    "\n",
    "# 假设 k=5\n",
    "k = 5\n",
    "bmi_cutoffs = dp_bmi_group(df, k)\n",
    "print(\"BMI分组界点:\", bmi_cutoffs)\n",
    "\n",
    "# -------------------------------\n",
    "# 4. 计算每组最佳检测时点\n",
    "# -------------------------------\n",
    "df['BMI_group'] = pd.cut(df['孕妇BMI'], bins=[0]+bmi_cutoffs+[np.inf], right=False)\n",
    "\n",
    "def best_GA_for_group(group_df, Y_target=0.04, coverage=0.95):\n",
    "    # 模拟随机效应 bi ~ N(0, σb^2)\n",
    "    # 简化假设 σb = 0.01\n",
    "    sigma_b = 0.01\n",
    "    n_sim = 1000\n",
    "    GA_samples = []\n",
    "    for _, row in group_df.iterrows():\n",
    "        bmi = row['孕妇BMI']\n",
    "        sims = calc_GAmin(Y_target, bmi) + np.random.normal(0, sigma_b, n_sim)\n",
    "        # 取使得达标概率 >= coverage 的最小GA\n",
    "        GA = np.percentile(sims, (1-coverage)*100)\n",
    "        GA_samples.append(GA)\n",
    "    return np.mean(GA_samples), np.percentile(GA_samples, 2.5), np.percentile(GA_samples, 97.5)\n",
    "\n",
    "result_list = []\n",
    "for name, group in df.groupby('BMI_group'):\n",
    "    GA_mean, GA_low, GA_high = best_GA_for_group(group)\n",
    "    result_list.append({\n",
    "        'BMI_group': str(name),\n",
    "        'sample_size': len(group),\n",
    "        'best_GA': GA_mean,\n",
    "        'CI_low': GA_low,\n",
    "        'CI_high': GA_high\n",
    "    })\n",
    "\n",
    "result_df = pd.DataFrame(result_list)\n",
    "print(result_df)\n",
    "\n",
    "# -------------------------------\n",
    "# 5. 保存结果\n",
    "# -------------------------------\n",
    "result_df.to_excel('NIPT_BMI_group_result.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b47e4166-6a4d-4576-8100-0c954f1d1fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据基本信息:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1082 entries, 0 to 1081\n",
      "Data columns (total 31 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   序号            1082 non-null   int64  \n",
      " 1   孕妇代码          1082 non-null   object \n",
      " 2   年龄            1082 non-null   int64  \n",
      " 3   身高            1082 non-null   float64\n",
      " 4   体重            1082 non-null   float64\n",
      " 5   末次月经          1082 non-null   object \n",
      " 6   IVF妊娠         1082 non-null   object \n",
      " 7   检测日期          1082 non-null   object \n",
      " 8   检测抽血次数        1082 non-null   int64  \n",
      " 9   检测孕周          1081 non-null   float64\n",
      " 10  孕妇BMI         1082 non-null   float64\n",
      " 11  原始读段数         1082 non-null   int64  \n",
      " 12  在参考基因组上比对的比例  1082 non-null   float64\n",
      " 13  重复读段的比例       1082 non-null   float64\n",
      " 14  唯一比对的读段数      1082 non-null   int64  \n",
      " 15  GC含量          1082 non-null   float64\n",
      " 16  13号染色体的Z值     1082 non-null   float64\n",
      " 17  18号染色体的Z值     1082 non-null   float64\n",
      " 18  21号染色体的Z值     1082 non-null   float64\n",
      " 19  X染色体的Z值       1082 non-null   float64\n",
      " 20  Y染色体的Z值       1082 non-null   float64\n",
      " 21  Y染色体浓度        1082 non-null   float64\n",
      " 22  X染色体浓度        1082 non-null   float64\n",
      " 23  13号染色体的GC含量   1082 non-null   float64\n",
      " 24  18号染色体的GC含量   1082 non-null   float64\n",
      " 25  21号染色体的GC含量   1082 non-null   float64\n",
      " 26  被过滤掉读段数的比例    1082 non-null   float64\n",
      " 27  染色体的非整倍体      1082 non-null   object \n",
      " 28  怀孕次数          1082 non-null   object \n",
      " 29  生产次数          1082 non-null   int64  \n",
      " 30  胎儿是否健康        1082 non-null   object \n",
      "dtypes: float64(18), int64(6), object(7)\n",
      "memory usage: 262.2+ KB\n",
      "None\n",
      "\n",
      "前5行数据:\n",
      "   序号  孕妇代码  年龄     身高    体重                 末次月经 IVF妊娠      检测日期  检测抽血次数  \\\n",
      "0   1  A001  31  160.0  72.0  2023-02-01 00:00:00  自然受孕  20230429       1   \n",
      "1   2  A001  31  160.0  73.0  2023-02-01 00:00:00  自然受孕  20230531       2   \n",
      "2   3  A001  31  160.0  73.0  2023-02-01 00:00:00  自然受孕  20230625       3   \n",
      "3   4  A001  31  160.0  74.0  2023-02-01 00:00:00  自然受孕  20230716       4   \n",
      "4   5  A002  32  149.0  74.0  2023-11-09 00:00:00  自然受孕  20240219       1   \n",
      "\n",
      "        检测孕周  ...    Y染色体浓度    X染色体浓度  13号染色体的GC含量  18号染色体的GC含量  21号染色体的GC含量  \\\n",
      "0  11.857143  ...  0.025936  0.038061     0.377069     0.389803     0.399399   \n",
      "1  15.857143  ...  0.034887  0.059572     0.371542     0.384771     0.391706   \n",
      "2  20.142857  ...  0.066171  0.075995     0.377449     0.390582     0.399480   \n",
      "3  22.857143  ...  0.061192  0.052305     0.375613     0.389251     0.397212   \n",
      "4  13.857143  ...  0.059230  0.059708     0.380260     0.393618     0.404868   \n",
      "\n",
      "   被过滤掉读段数的比例  染色体的非整倍体  怀孕次数  生产次数  胎儿是否健康  \n",
      "0    0.027484         0     1     0       是  \n",
      "1    0.019617         0     1     0       是  \n",
      "2    0.022312         0     1     0       是  \n",
      "3    0.023280         0     1     0       是  \n",
      "4    0.024212         0     2     1       否  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "回归方程: Y = -0.001706 * BMI + 0.132276\n",
      "BMI分组界点: [np.float64(28.125), np.float64(28.515625), np.float64(28.515625), np.float64(28.90625)]\n",
      "运行过程中出现错误: Bin edges must be unique: Index([0.0, 28.125, 28.515625, 28.515625, 28.90625, inf], dtype='float64').\n",
      "You can drop duplicate edges by setting the 'duplicates' kwarg\n",
      "尝试检查数据或调整参数\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# -------------------------------\n",
    "# 1. 数据准备和回归分析\n",
    "# -------------------------------\n",
    "# 假设df已经包含数据\n",
    "print(\"数据基本信息:\")\n",
    "print(df.info())\n",
    "print(\"\\n前5行数据:\")\n",
    "print(df.head())\n",
    "\n",
    "# 确保数据类型正确\n",
    "X = df[['孕妇BMI']].astype(float)\n",
    "y = df['Y染色体浓度'].astype(float)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "a = model.coef_[0]\n",
    "c = model.intercept_\n",
    "print(f\"回归方程: Y = {a:.6f} * BMI + {c:.6f}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 2. 定义计算最小GA的函数\n",
    "# -------------------------------\n",
    "def calc_GAmin(Y_target, bmi):\n",
    "    \"\"\"计算达到目标Y浓度所需的最小GA\"\"\"\n",
    "    return (Y_target - c - a * bmi) / a\n",
    "\n",
    "# -------------------------------\n",
    "# 3. 动态规划分组\n",
    "# -------------------------------\n",
    "def dp_bmi_group(df, k):\n",
    "    n = len(df)\n",
    "    BMI = df['孕妇BMI'].values\n",
    "    \n",
    "    # 计算方差矩阵\n",
    "    var_matrix = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            var_matrix[i,j] = np.var(BMI[i:j+1])\n",
    "    \n",
    "    # DP初始化\n",
    "    dp = np.full((k, n), np.inf)\n",
    "    track = np.zeros((k, n), dtype=int)\n",
    "    \n",
    "    for i in range(n):\n",
    "        dp[0,i] = var_matrix[0,i]\n",
    "    \n",
    "    for group in range(1, k):\n",
    "        for i in range(group, n):\n",
    "            for j in range(group-1, i):\n",
    "                cost = dp[group-1,j] + var_matrix[j+1,i]\n",
    "                if cost < dp[group,i]:\n",
    "                    dp[group,i] = cost\n",
    "                    track[group,i] = j\n",
    "    \n",
    "    # 回溯分组界点\n",
    "    borders = []\n",
    "    idx = n-1\n",
    "    for group in reversed(range(1, k)):\n",
    "        j = track[group, idx]\n",
    "        borders.append(BMI[j])\n",
    "        idx = j\n",
    "    borders = sorted(borders)\n",
    "    return borders\n",
    "\n",
    "# 假设 k=5\n",
    "k = 5\n",
    "try:\n",
    "    bmi_cutoffs = dp_bmi_group(df, k)\n",
    "    print(\"BMI分组界点:\", bmi_cutoffs)\n",
    "    \n",
    "    # -------------------------------\n",
    "    # 4. 计算每组最佳检测时点\n",
    "    # -------------------------------\n",
    "    df['BMI_group'] = pd.cut(df['孕妇BMI'], bins=[0]+bmi_cutoffs+[np.inf], right=False)\n",
    "    \n",
    "    def best_GA_for_group(group_df, Y_target=0.04, coverage=0.95):\n",
    "        # 模拟随机效应 bi ~ N(0, σb^2)\n",
    "        # 简化假设 σb = 0.01\n",
    "        sigma_b = 0.01\n",
    "        n_sim = 1000\n",
    "        GA_samples = []\n",
    "        for _, row in group_df.iterrows():\n",
    "            bmi = row['孕妇BMI']\n",
    "            sims = calc_GAmin(Y_target, bmi) + np.random.normal(0, sigma_b, n_sim)\n",
    "            # 取使得达标概率 >= coverage 的最小GA\n",
    "            GA = np.percentile(sims, (1-coverage)*100)\n",
    "            GA_samples.append(GA)\n",
    "        return np.mean(GA_samples), np.percentile(GA_samples, 2.5), np.percentile(GA_samples, 97.5)\n",
    "    \n",
    "    result_list = []\n",
    "    for name, group in df.groupby('BMI_group'):\n",
    "        GA_mean, GA_low, GA_high = best_GA_for_group(group)\n",
    "        result_list.append({\n",
    "            'BMI_group': str(name),\n",
    "            'sample_size': len(group),\n",
    "            'best_GA': GA_mean,\n",
    "            'CI_low': GA_low,\n",
    "            'CI_high': GA_high\n",
    "        })\n",
    "    \n",
    "    result_df = pd.DataFrame(result_list)\n",
    "    print(\"\\n分组结果:\")\n",
    "    print(result_df)\n",
    "    \n",
    "    # -------------------------------\n",
    "    # 5. 保存结果\n",
    "    # -------------------------------\n",
    "    result_df.to_excel('NIPT_BMI_group_result.xlsx', index=False)\n",
    "    print(\"\\n结果已保存到 'NIPT_BMI_group_result.xlsx'\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"运行过程中出现错误: {e}\")\n",
    "    print(\"尝试检查数据或调整参数\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd920cfc-a0eb-46e1-8b8a-e03786030155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始数据分析...\n",
      "回归方程: Y = -0.001706 * BMI + 0.132276\n",
      "开始动态规划分组，k=5，数据量=1082\n",
      "计算方差矩阵...\n",
      "计算方差矩阵进度: 0/1082\n",
      "计算方差矩阵进度: 100/1082\n",
      "计算方差矩阵进度: 200/1082\n",
      "计算方差矩阵进度: 300/1082\n",
      "计算方差矩阵进度: 400/1082\n",
      "计算方差矩阵进度: 500/1082\n",
      "计算方差矩阵进度: 600/1082\n",
      "计算方差矩阵进度: 700/1082\n",
      "计算方差矩阵进度: 800/1082\n",
      "计算方差矩阵进度: 900/1082\n",
      "计算方差矩阵进度: 1000/1082\n",
      "进行动态规划计算...\n",
      "处理第 2 组...\n",
      "  进度: 100/1082\n",
      "  进度: 200/1082\n",
      "  进度: 300/1082\n",
      "  进度: 400/1082\n",
      "  进度: 500/1082\n",
      "  进度: 600/1082\n",
      "  进度: 700/1082\n",
      "  进度: 800/1082\n",
      "  进度: 900/1082\n",
      "  进度: 1000/1082\n",
      "处理第 3 组...\n",
      "  进度: 100/1082\n",
      "  进度: 200/1082\n",
      "  进度: 300/1082\n",
      "  进度: 400/1082\n",
      "  进度: 500/1082\n",
      "  进度: 600/1082\n",
      "  进度: 700/1082\n",
      "  进度: 800/1082\n",
      "  进度: 900/1082\n",
      "  进度: 1000/1082\n",
      "处理第 4 组...\n",
      "  进度: 100/1082\n",
      "  进度: 200/1082\n",
      "  进度: 300/1082\n",
      "  进度: 400/1082\n",
      "  进度: 500/1082\n",
      "  进度: 600/1082\n",
      "  进度: 700/1082\n",
      "  进度: 800/1082\n",
      "  进度: 900/1082\n",
      "  进度: 1000/1082\n",
      "处理第 5 组...\n",
      "  进度: 100/1082\n",
      "  进度: 200/1082\n",
      "  进度: 300/1082\n",
      "  进度: 400/1082\n",
      "  进度: 500/1082\n",
      "  进度: 600/1082\n",
      "  进度: 700/1082\n",
      "  进度: 800/1082\n",
      "  进度: 900/1082\n",
      "  进度: 1000/1082\n",
      "动态规划完成，耗时: 35.71 秒\n",
      "BMI分组界点: [np.float64(28.125), np.float64(28.515625), np.float64(28.515625), np.float64(28.90625)]\n",
      "开始计算最佳检测时点...\n",
      "运行过程中出现错误: Bin edges must be unique: Index([0.0, 28.125, 28.515625, 28.515625, 28.90625, inf], dtype='float64').\n",
      "You can drop duplicate edges by setting the 'duplicates' kwarg\n",
      "\n",
      "尝试使用简化分组方法...\n",
      "使用分位数分组界点: [29.95648448 31.16443416 32.67554956 34.44531691]\n",
      "处理分组: [0.0, 29.956)\n",
      "简化方法也失败: name 'best_GA_for_group' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_14640\\3756536702.py\", line 90, in <module>\n",
      "    df['BMI_group'] = pd.cut(df['孕妇BMI'], bins=[0] + bmi_cutoffs + [np.inf], right=False)\n",
      "                      ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\reshape\\tile.py\", line 257, in cut\n",
      "    fac, bins = _bins_to_cuts(\n",
      "                ~~~~~~~~~~~~~^\n",
      "        x_idx,\n",
      "        ^^^^^^\n",
      "    ...<6 lines>...\n",
      "        ordered=ordered,\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\reshape\\tile.py\", line 443, in _bins_to_cuts\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Bin edges must be unique: Index([0.0, 28.125, 28.515625, 28.515625, 28.90625, inf], dtype='float64').\n",
      "You can drop duplicate edges by setting the 'duplicates' kwarg\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_14640\\3756536702.py:140: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for name, group in df.groupby('BMI_group'):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import time\n",
    "\n",
    "# -------------------------------\n",
    "# 1. 数据准备和回归分析\n",
    "# -------------------------------\n",
    "print(\"开始数据分析...\")\n",
    "X = df[['孕妇BMI']].astype(float)\n",
    "y = df['Y染色体浓度'].astype(float)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "a = model.coef_[0]\n",
    "c = model.intercept_\n",
    "print(f\"回归方程: Y = {a:.6f} * BMI + {c:.6f}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 2. 定义计算最小GA的函数\n",
    "# -------------------------------\n",
    "def calc_GAmin(Y_target, bmi):\n",
    "    \"\"\"计算达到目标Y浓度所需的最小GA\"\"\"\n",
    "    return (Y_target - c - a * bmi) / a\n",
    "\n",
    "# -------------------------------\n",
    "# 3. 动态规划分组（优化版本）\n",
    "# -------------------------------\n",
    "def dp_bmi_group(df, k):\n",
    "    print(f\"开始动态规划分组，k={k}，数据量={len(df)}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    n = len(df)\n",
    "    BMI = df['孕妇BMI'].values\n",
    "    \n",
    "    # 计算方差矩阵（优化：只计算上三角部分）\n",
    "    print(\"计算方差矩阵...\")\n",
    "    var_matrix = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        if i % 100 == 0:  # 每100行显示进度\n",
    "            print(f\"计算方差矩阵进度: {i}/{n}\")\n",
    "        for j in range(i, n):\n",
    "            var_matrix[i,j] = np.var(BMI[i:j+1])\n",
    "    \n",
    "    # DP初始化\n",
    "    dp = np.full((k, n), np.inf)\n",
    "    track = np.zeros((k, n), dtype=int)\n",
    "    \n",
    "    # 初始化第一组\n",
    "    for i in range(n):\n",
    "        dp[0,i] = var_matrix[0,i]\n",
    "    \n",
    "    # 动态规划\n",
    "    print(\"进行动态规划计算...\")\n",
    "    for group in range(1, k):\n",
    "        print(f\"处理第 {group+1} 组...\")\n",
    "        for i in range(group, n):\n",
    "            if i % 100 == 0:  # 每100个显示进度\n",
    "                print(f\"  进度: {i}/{n}\")\n",
    "            for j in range(group-1, i):\n",
    "                cost = dp[group-1,j] + var_matrix[j+1,i]\n",
    "                if cost < dp[group,i]:\n",
    "                    dp[group,i] = cost\n",
    "                    track[group,i] = j\n",
    "    \n",
    "    # 回溯分组界点\n",
    "    borders = []\n",
    "    idx = n-1\n",
    "    for group in reversed(range(1, k)):\n",
    "        j = track[group, idx]\n",
    "        borders.append(BMI[j])\n",
    "        idx = j\n",
    "    \n",
    "    borders = sorted(borders)\n",
    "    end_time = time.time()\n",
    "    print(f\"动态规划完成，耗时: {end_time - start_time:.2f} 秒\")\n",
    "    return borders\n",
    "\n",
    "# 尝试运行动态规划\n",
    "try:\n",
    "    k = 5\n",
    "    bmi_cutoffs = dp_bmi_group(df, k)\n",
    "    print(\"BMI分组界点:\", bmi_cutoffs)\n",
    "    \n",
    "    # -------------------------------\n",
    "    # 4. 计算每组最佳检测时点\n",
    "    # -------------------------------\n",
    "    print(\"开始计算最佳检测时点...\")\n",
    "    df['BMI_group'] = pd.cut(df['孕妇BMI'], bins=[0] + bmi_cutoffs + [np.inf], right=False)\n",
    "    \n",
    "    def best_GA_for_group(group_df, Y_target=0.04, coverage=0.95):\n",
    "        sigma_b = 0.01\n",
    "        n_sim = 1000\n",
    "        GA_samples = []\n",
    "        for _, row in group_df.iterrows():\n",
    "            bmi = row['孕妇BMI']\n",
    "            sims = calc_GAmin(Y_target, bmi) + np.random.normal(0, sigma_b, n_sim)\n",
    "            GA = np.percentile(sims, (1 - coverage) * 100)\n",
    "            GA_samples.append(GA)\n",
    "        return np.mean(GA_samples), np.percentile(GA_samples, 2.5), np.percentile(GA_samples, 97.5)\n",
    "    \n",
    "    result_list = []\n",
    "    for name, group in df.groupby('BMI_group'):\n",
    "        print(f\"处理分组: {name}\")\n",
    "        GA_mean, GA_low, GA_high = best_GA_for_group(group)\n",
    "        result_list.append({\n",
    "            'BMI_group': str(name),\n",
    "            'sample_size': len(group),\n",
    "            'best_GA': GA_mean,\n",
    "            'CI_low': GA_low,\n",
    "            'CI_high': GA_high\n",
    "        })\n",
    "    \n",
    "    result_df = pd.DataFrame(result_list)\n",
    "    print(\"\\n分组结果:\")\n",
    "    print(result_df)\n",
    "    \n",
    "    # -------------------------------\n",
    "    # 5. 保存结果\n",
    "    # -------------------------------\n",
    "    result_df.to_excel('NIPT_BMI_group_result.xlsx', index=False)\n",
    "    print(\"\\n结果已保存到 'NIPT_BMI_group_result.xlsx'\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"运行过程中出现错误: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    \n",
    "    # 如果动态规划太慢，尝试简化版本\n",
    "    print(\"\\n尝试使用简化分组方法...\")\n",
    "    try:\n",
    "        # 使用分位数进行简单分组\n",
    "        bmi_cutoffs = np.quantile(df['孕妇BMI'], [0.2, 0.4, 0.6, 0.8])\n",
    "        print(\"使用分位数分组界点:\", bmi_cutoffs)\n",
    "        \n",
    "        df['BMI_group'] = pd.cut(df['孕妇BMI'], bins=[0] + list(bmi_cutoffs) + [np.inf], right=False)\n",
    "        \n",
    "        result_list = []\n",
    "        for name, group in df.groupby('BMI_group'):\n",
    "            print(f\"处理分组: {name}\")\n",
    "            GA_mean, GA_low, GA_high = best_GA_for_group(group)\n",
    "            result_list.append({\n",
    "                'BMI_group': str(name),\n",
    "                'sample_size': len(group),\n",
    "                'best_GA': GA_mean,\n",
    "                'CI_low': GA_low,\n",
    "                'CI_high': GA_high\n",
    "            })\n",
    "        \n",
    "        result_df = pd.DataFrame(result_list)\n",
    "        print(\"\\n简化分组结果:\")\n",
    "        print(result_df)\n",
    "        result_df.to_excel('NIPT_BMI_group_result_simple.xlsx', index=False)\n",
    "        print(\"\\n简化结果已保存到 'NIPT_BMI_group_result_simple.xlsx'\")\n",
    "        \n",
    "    except Exception as e2:\n",
    "        print(f\"简化方法也失败: {e2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87fcf92a-6225-4464-9f83-e098ba9fba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmi_bins = [0] + sorted(set(bmi_cutoffs)) + [np.inf]\n",
    "df['BMI_group'] = pd.cut(df['孕妇BMI'], bins=bmi_bins, right=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa75b0a4-883c-452d-9b38-60b02b3ad64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmi_cutoffs_unique = sorted(list(set(bmi_cutoffs)))\n",
    "df['BMI_group'] = pd.cut(df['孕妇BMI'],\n",
    "                         bins=[0]+bmi_cutoffs_unique+[np.inf],\n",
    "                         right=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef3df198-f371-47f2-9ab5-81d1cc58745b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY染色体浓度\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     25\u001b[0m model \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[1;32m---> 26\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X, y)\n\u001b[0;32m     28\u001b[0m a, b \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcoef_\n\u001b[0;32m     29\u001b[0m c \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mintercept_\n",
      "File \u001b[1;32mD:\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:601\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    597\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    599\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 601\u001b[0m X, y \u001b[38;5;241m=\u001b[39m validate_data(\n\u001b[0;32m    602\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    603\u001b[0m     X,\n\u001b[0;32m    604\u001b[0m     y,\n\u001b[0;32m    605\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m    606\u001b[0m     y_numeric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    607\u001b[0m     multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    608\u001b[0m     force_writeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    609\u001b[0m )\n\u001b[0;32m    611\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[1;32mD:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2961\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2959\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m   2960\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2961\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m   2962\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mD:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1370\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1366\u001b[0m     )\n\u001b[0;32m   1368\u001b[0m ensure_all_finite \u001b[38;5;241m=\u001b[39m _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[1;32m-> 1370\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1371\u001b[0m     X,\n\u001b[0;32m   1372\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   1373\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1374\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1375\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   1376\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1377\u001b[0m     force_writeable\u001b[38;5;241m=\u001b[39mforce_writeable,\n\u001b[0;32m   1378\u001b[0m     ensure_all_finite\u001b[38;5;241m=\u001b[39mensure_all_finite,\n\u001b[0;32m   1379\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m   1380\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[0;32m   1381\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1382\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[0;32m   1383\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1384\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1385\u001b[0m )\n\u001b[0;32m   1387\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1389\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mD:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1107\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[1;32m-> 1107\u001b[0m     _assert_all_finite(\n\u001b[0;32m   1108\u001b[0m         array,\n\u001b[0;32m   1109\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m   1110\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m   1111\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mensure_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1112\u001b[0m     )\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1116\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:120\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m _assert_all_finite_element_wise(\n\u001b[0;32m    121\u001b[0m     X,\n\u001b[0;32m    122\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n\u001b[0;32m    123\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[0;32m    124\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n\u001b[0;32m    125\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    126\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    127\u001b[0m )\n",
      "File \u001b[1;32mD:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:169\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    168\u001b[0m     )\n\u001b[1;32m--> 169\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import root_scalar\n",
    "from scipy.stats import norm\n",
    "\n",
    "# -------------------------------\n",
    "# 1. 读取数据\n",
    "# -------------------------------\n",
    "df = pd.read_excel('male.xlsx')\n",
    "\n",
    "# 确认列名一致\n",
    "# df.columns\n",
    "\n",
    "# -------------------------------\n",
    "# 2. 计算Y染色体达标时间\n",
    "# 模型: Yij = f(GAij, BMIi, β) + bi + ϵij\n",
    "# 我们用线性近似 f(GA,BMI)=a*GA+b*BMI+c\n",
    "# -------------------------------\n",
    "# 线性近似拟合 Y ~ GA + BMI\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = df[['检测孕周', '孕妇BMI']]\n",
    "y = df['Y染色体浓度']\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "a, b = model.coef_\n",
    "c = model.intercept_\n",
    "\n",
    "# 定义个体达标函数\n",
    "def calc_GAmin(Y_target, BMIi):\n",
    "    # Y = a*GA + b*BMI + c => GA = (Y - b*BMI - c)/a\n",
    "    return (Y_target - b*BMIi - c)/a\n",
    "\n",
    "df['GA_min'] = df['孕妇BMI'].apply(lambda bmi: calc_GAmin(0.04, bmi))\n",
    "# 对未达标设定右截断 25 周\n",
    "df['GA_min'] = df['GA_min'].apply(lambda x: x if x <= 25 else 25)\n",
    "\n",
    "# -------------------------------\n",
    "# 3. BMI分组动态规划优化\n",
    "# -------------------------------\n",
    "def dp_bmi_group(df, k):\n",
    "    # 排序BMI\n",
    "    df_sorted = df.sort_values('孕妇BMI').reset_index(drop=True)\n",
    "    BMI = df_sorted['孕妇BMI'].values\n",
    "    GAmin = df_sorted['GA_min'].values\n",
    "    n = len(BMI)\n",
    "    \n",
    "    # 预计算区间方差\n",
    "    var_matrix = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            var_matrix[i,j] = np.var(GAmin[i:j+1])\n",
    "    \n",
    "    # DP初始化\n",
    "    dp = np.full((k, n), np.inf)\n",
    "    track = np.zeros((k, n), dtype=int)\n",
    "    \n",
    "    for i in range(n):\n",
    "        dp[0,i] = var_matrix[0,i]\n",
    "    \n",
    "    for group in range(1, k):\n",
    "        for i in range(group, n):\n",
    "            for j in range(group-1, i):\n",
    "                cost = dp[group-1,j] + var_matrix[j+1,i]\n",
    "                if cost < dp[group,i]:\n",
    "                    dp[group,i] = cost\n",
    "                    track[group,i] = j\n",
    "    \n",
    "    # 回溯分组界点\n",
    "    borders = []\n",
    "    idx = n-1\n",
    "    for group in reversed(range(1, k)):\n",
    "        j = track[group, idx]\n",
    "        borders.append(BMI[j])\n",
    "        idx = j\n",
    "    borders = sorted(borders)\n",
    "    return borders\n",
    "\n",
    "# 假设 k=5\n",
    "k = 5\n",
    "bmi_cutoffs = dp_bmi_group(df, k)\n",
    "print(\"BMI分组界点:\", bmi_cutoffs)\n",
    "\n",
    "# -------------------------------\n",
    "# 4. 计算每组最佳检测时点\n",
    "# -------------------------------\n",
    "df['BMI_group'] = pd.cut(df['孕妇BMI'], bins=[0]+bmi_cutoffs+[np.inf], right=False)\n",
    "\n",
    "def best_GA_for_group(group_df, Y_target=0.04, coverage=0.95):\n",
    "    # 模拟随机效应 bi ~ N(0, σb^2)\n",
    "    # 简化假设 σb = 0.01\n",
    "    sigma_b = 0.01\n",
    "    n_sim = 1000\n",
    "    GA_samples = []\n",
    "    for _, row in group_df.iterrows():\n",
    "        bmi = row['孕妇BMI']\n",
    "        sims = calc_GAmin(Y_target, bmi) + np.random.normal(0, sigma_b, n_sim)\n",
    "        # 取使得达标概率 >= coverage 的最小GA\n",
    "        GA = np.percentile(sims, (1-coverage)*100)\n",
    "        GA_samples.append(GA)\n",
    "    return np.mean(GA_samples), np.percentile(GA_samples, 2.5), np.percentile(GA_samples, 97.5)\n",
    "\n",
    "result_list = []\n",
    "for name, group in df.groupby('BMI_group'):\n",
    "    GA_mean, GA_low, GA_high = best_GA_for_group(group)\n",
    "    result_list.append({\n",
    "        'BMI_group': str(name),\n",
    "        'sample_size': len(group),\n",
    "        'best_GA': GA_mean,\n",
    "        'CI_low': GA_low,\n",
    "        'CI_high': GA_high\n",
    "    })\n",
    "\n",
    "result_df = pd.DataFrame(result_list)\n",
    "print(result_df)\n",
    "\n",
    "# -------------------------------\n",
    "# 5. 保存结果\n",
    "# -------------------------------\n",
    "result_df.to_excel('NIPT_BMI_group_result.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5623f3-72f9-4040-9cef-69f2f311ae0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
